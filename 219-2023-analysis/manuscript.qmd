---
title: "Replication of Brydevall et al. 2018"
author: "Josh de Leeuw"
format: 
  html:
    df-print: kable
editor: visual
---

```{r}
#| label: Load libraries
#| echo: false
#| message: false
#| warning: false

library(dplyr)
library(ggplot2)
library(readr)
library(ez)
library(tidyr)
library(osfr)
```

```{r}
#| label: Get preprocessed data from OSF
#| include: false
#| echo: false

osf_retrieve_node("2pxf4") %>%
  osf_ls_files() %>%
  osf_download(path="data/preprocessed/", conflicts="skip")
```

## Methods

```{r}
#| label: Load the Behavioral Data
#| echo: false
#| message: false


data.behavioral <- read_csv("data/preprocessed/behavioral.csv")
```

### Participants

```{r}
#| label: Count participants
#| echo: false

n.participants <- data.behavioral %>% pull(subject) %>% unique() %>% length()
```

`r n.participants` Vassar College students participated in this study. All participants were right-handed.

## Results

### Behavioral

```{r}
#| label: Attention check calculations
#| echo: false

attention.check.responses <- data.behavioral %>%
  filter(task=="catch", phase=="test", card_id == catch_n) %>%
  group_by(subject) %>%
  summarize(successes = sum(rt < 1500, na.rm=TRUE), mean_rt = mean(rt, na.rm=TRUE))

attention.check.tally <- attention.check.responses %>% group_by(successes) %>% summarize(n=n())

attention.check.rt.m <- attention.check.responses %>% pull(mean_rt) %>%
  mean() %>% round(0)
attention.check.rt.sd <- attention.check.responses %>% pull(mean_rt) %>%
  sd() %>% round(0)


attention.check.failures <- attention.check.responses %>% filter(successes < 3)
```

There were five attention check trials, one during each block, throughout the experiment. `r attention.check.tally %>% filter(successes==5) %>% pull(n)` of `r n.participants` responded in time to all 5 attention checks, and `r attention.check.tally %>% filter(successes==4) %>% pull(n)` responded correctly to 4 of the 5 attention checks. The average response time was `r attention.check.rt.m`ms (*SD* = `r attention.check.rt.sd`). As per our pre-registered criteria, we excluded `r nrow(attention.check.failures)` participants for failing more than 2 attention checks (defined as a response time greater than 1,500ms).

```{r}
#| label: Compute RPEs and IPEs
#| echo: false
#| message: false

hand.information <- data.behavioral %>% 
  filter(phase=='test', task=='reveal') %>%
  group_by(subject) %>%
  mutate(hand_id = rep(1:80, each=5)) %>%
  ungroup() %>%
  mutate(losses_so_far = (card_id-1) - wins_so_far) %>%
  select(subject, hand_id, card_id, card_value, wins_so_far, losses_so_far, outcome)

hand.information.with.rpe <- hand.information %>%
  mutate(
    wp_before = pbinom(2-losses_so_far, 5-(card_id-1), 0.5), 
    wp_after = pbinom(2-(losses_so_far+(1-card_value)), 5-card_id, 0.5), 
    rpe = wp_after-wp_before)

entropy <- function(p){
  return(ifelse(p == 0 | p == 1, 0, -p*log2(p) - (1-p)*log2(1-p)))
}

hand.information.with.rpe.and.ipe <- hand.information.with.rpe %>%
  mutate(wp_alternative = pbinom(2-(losses_so_far+card_value), 5-card_id, 0.5)) %>%
  mutate(information = entropy(wp_before) - entropy(wp_after),
         information_alt = entropy(wp_before) - entropy(wp_alternative),
         information_expected = (information + information_alt) / 2,
         ipe = information - information_expected) %>%
  mutate(rpe_type = case_when(
    rpe > 0 ~ "Positive",
    rpe < 0 ~ "Negative",
    rpe == 0 ~ "None")) %>%
  mutate(ipe_type = case_when(
    ipe > 0 ~ "Positive",
    ipe < 0 ~ "Negative",
    ipe == 0 ~ "None"))

hand.information.minimal.set <- hand.information.with.rpe.and.ipe %>%
  select(subject, hand_id, card_id, rpe, ipe, rpe_type, ipe_type)
```

### EEG

```{r}
#| label: Load EEG data
#| echo: false
#| message: false

data.eeg.filtered <- read_csv('data/preprocessed/eeg.csv') %>%
  filter(good_segment == TRUE, electrode %in% c("Cz", "Fz"))

```

```{r}
#| label: Merge RPE and IPE info into EEG data
#| echo: false
#| message: false

data.eeg.filtered.rpe.ipe <- data.eeg.filtered %>%
  left_join(hand.information.minimal.set, by=c("subject", "hand_id", "card_id"))

```

```{r}
#| label: Count usable segments for RPEs
#| echo: false
#| message: false

rpe.segments <- data.eeg.filtered.rpe.ipe %>%
  filter(rpe_type != "None") %>%
  group_by(subject, electrode, hand_id, card_id, rpe_type) %>%
  slice_head(n=1) %>%
  group_by(subject, electrode, rpe_type) %>%
  summarize(n=n())
```

```{r}
#| label: Count usable segments for IPEs
#| echo: false
#| message: false

ipe.segments <- data.eeg.filtered.rpe.ipe %>%
  filter(ipe_type != "None") %>%
  group_by(subject, electrode, hand_id, card_id, ipe_type) %>%
  slice_head(n=1) %>%
  group_by(subject, electrode, ipe_type) %>%
  summarize(n = n())
```

```{r}
#| label: Exclude bad EEG
#| echo: false

rpe.good.subjects <- rpe.segments %>%
  group_by(subject) %>%
  summarize(include = all(n >= 20)) %>%
  filter(include == TRUE) %>%
  pull(subject)

ipe.good.subjects <- ipe.segments %>%
  group_by(subject) %>%
  summarize(include = all(n >= 20)) %>%
  filter(include == TRUE) %>%
  pull(subject)
```

We pre-registered an inclusion criteria that a participant must have at least 20 usable epochs of data of a particular event type in order to be included in the corresponding analyses. `r rpe.good.subjects %>% length()` subjects were included in the RPE analysis and `r ipe.good.subjects %>% length()` subjects were included in the IPE analysis. The average number of usable epochs for the RPE analysis in an individual subject was `r rpe.segments %>% filter(subject %in% rpe.good.subjects) %>% pull(n) %>% mean() %>% round(0)`, *SD*=`r rpe.segments %>% filter(subject %in% rpe.good.subjects) %>% pull(n) %>% sd() %>% round(0)`. The average number of usable epochs for the IPE analysis was `r ipe.segments %>% filter(subject %in% ipe.good.subjects) %>% pull(n) %>% mean() %>% round(0)`, *SD*=`r ipe.segments %>% filter(subject %in% ipe.good.subjects) %>% pull(n) %>% sd() %>% round(0)`.

```{r}
#| label: Define ERP time window
#| echo: false

frn.window <- 200:350
```

```{r}
#| label: Generate data for Grand Averages
#| echo: false
#| message: false

rpe.erp.data.subject <- data.eeg.filtered.rpe.ipe %>%
  filter(rpe_type != "None") %>%
  filter(subject %in% rpe.good.subjects) %>%
  group_by(subject, electrode, t, rpe_type) %>%
  summarize(m.subject = mean(v))

rpe.erp.data.group <- rpe.erp.data.subject %>%
  group_by(electrode, t, rpe_type) %>%
  summarize(m = mean(m.subject), se = sd(m.subject)/sqrt(n())) %>%
  mutate(error_type = "Reward Prediction Error", error_sign = rpe_type)

ipe.erp.data.subject <- data.eeg.filtered.rpe.ipe %>%
  filter(ipe_type != "None") %>%
  filter(subject %in% ipe.good.subjects) %>%
  group_by(subject, electrode, t, ipe_type) %>%
  summarize(m.subject = mean(v))

ipe.erp.data.group <- ipe.erp.data.subject %>%
  group_by(electrode, t, ipe_type) %>%
  summarize(m = mean(m.subject), se = sd(m.subject)/sqrt(n())) %>%
  mutate(error_type = "Information Prediction Error", error_sign = ipe_type)

erp.data <- rpe.erp.data.group %>% bind_rows(ipe.erp.data.group) %>%
  select(-rpe_type, -ipe_type)

```

```{r}
#| label: fig-grand-averages
#| echo: false
#| fig-cap: Grand average ERPs for both electrode sites (Cz, Fz) and both error types (Information Prediction and Reward Prediction). The critical time window for our analysis, 200-350ms, is highlighted.

ggplot(erp.data, aes(x=t, y=m, ymin=m-se, ymax=m+se, color=error_sign, fill=error_sign))+
  facet_grid(error_type ~ electrode)+
  geom_hline(yintercept = 0)+
  geom_vline(xintercept = 0)+
  annotate("rect", xmin=min(frn.window), xmax=max(frn.window), ymin=-Inf, ymax=Inf, alpha=0.4)+
  geom_ribbon(color=NA, alpha = 0.2)+
  geom_line()+
  scale_y_reverse()+
  scale_color_brewer(type="qual", palette = "Set1", name="Error Direction")+
  scale_fill_brewer(type="qual", palette = "Set1", name="Error Direction")+
  labs(x="Time since card value revealed (ms)", y="Microvolts")+
  theme_minimal()+
  theme(panel.grid = element_blank())

```

```{r}
#| label: Difference wave summary data
#| echo: false
#| message: false

difference.wave.data.rpe <- rpe.erp.data.subject %>%
  pivot_wider(names_from = rpe_type, values_from = m.subject) %>%
  mutate(difference.subject = Positive - Negative)

difference.wave.summary.rpe <- difference.wave.data.rpe %>%
  group_by(electrode, t) %>%
  summarize(difference = mean(difference.subject), se=sd(difference.subject)/sqrt(n())) %>%
  mutate(error_type = "Reward Prediction Error")

difference.wave.data.ipe <- ipe.erp.data.subject %>%
  pivot_wider(names_from = ipe_type, values_from = m.subject) %>%
  mutate(difference.subject = Positive - Negative)

difference.wave.summary.ipe <- difference.wave.data.ipe %>%
  group_by(electrode, t) %>%
  summarize(difference = mean(difference.subject), se=sd(difference.subject)/sqrt(n())) %>%
  mutate(error_type = "Information Prediction Error")

difference.erp.data <- difference.wave.summary.rpe %>% bind_rows(difference.wave.summary.ipe)

```

```{r}
#| label: fig-difference-waves
#| echo: false
#| fig-cap: Grand average difference wave ERPs for both electrode sites (Cz, Fz). Values above 0 indicate that positive errors had a more positive ERP than negative errors. The critical time window for our analysis, 200-350ms, is highlighted.

ggplot(difference.erp.data, aes(x=t,y=difference, ymin=difference-se, ymax=difference+se, color=error_type, fill=error_type))+
  geom_hline(yintercept = 0)+
  geom_vline(xintercept = 0)+
  annotate("rect", xmin=min(frn.window), xmax=max(frn.window), ymin=-Inf, ymax=Inf, alpha=0.1)+
  geom_ribbon(color=NA, alpha=0.2)+
  geom_line()+
   scale_color_brewer(type="qual", palette = "Set2", name="Error Type")+
  scale_fill_brewer(type="qual", palette = "Set2", name="Error Type")+
  facet_grid(electrode~.)+
  labs(x="Time since card value revealed (ms)", y="Positive - Negative Prediction Errors\n(Microvolts)")+
  theme_minimal()+
  theme(panel.grid = element_blank())

```

Brydevall et al. reported that the ERPs in the 200-350ms window following positive prediction errors were more positive than the ERPs following negative prediction errors, for both information prediction errors and reward prediciton errors. Following our pre-registration, we ran two ANOVAs to see if there was a main effect of reward type (positive vs. negative). We included electrode (Cz vs. Fz) as a factor, as well as the interaction between reward type and electrode.

```{r}
#| label: Compute ANOVA data
#| echo: false
#| message: false

rpe.anova.data <- rpe.erp.data.subject %>%
  filter(t %in% frn.window) %>%
  group_by(subject, electrode, rpe_type) %>%
  summarize(M = mean(m.subject))

ipe.anova.data <- ipe.erp.data.subject %>%
  filter(t %in% frn.window) %>%
  group_by(subject, electrode, ipe_type) %>%
  summarize(M = mean(m.subject))
```

```{r}
#| label: RPE ANOVA
#| echo: false
#| warning: false

rpe.anova <- ezANOVA(rpe.anova.data, dv=M, wid=subject, within=c(electrode, rpe_type))

rpe.anova$ANOVA
```

The ANOVA table above shows that there is no significant effect of error type for reward prediction errors.

```{r}
#| label: IPE ANOVA
#| echo: false
#| warning: false

ipe.anova <- ezANOVA(ipe.anova.data, dv=M, wid=subject, within=c(electrode, ipe_type))

ipe.anova$ANOVA
```

However, there was a significant effect of error type for information prediction errors. This confirms the pattern that is evident in both @fig-grand-averages and @fig-difference-waves, where there is no clear visual difference between the ERPs for reward prediction errors, but there is a clear difference for information prediction errors.

### Exploratory Analysis

```{r}
trial.level.data <- data.eeg.filtered.rpe.ipe %>%
  filter(subject %in% rpe.good.subjects) %>%
  filter(t %in% frn.window) %>%
  group_by(subject, hand_id, card_id, electrode, rpe_type, rpe, ipe) %>%
  summarize(m.subject = mean(v))
```

```{r}
library(brms)

fit <- brm(m.subject ~ rpe + ipe + (1 + rpe + ipe | subject/hand_id), data=trial.level.data, cores=4)
```


```{r}
summary(fit)
```


```{r}
unsigned_fit <- brm(m.subject ~ rpe + ipe + (1 + rpe + ipe | subject/hand_id), data=trial.level.data %>% mutate(ipe=abs(ipe), rpe=abs(rpe)), cores=4)
```

```{r}
summary(unsigned_fit)
```

```{r}
abs.plot.data <- data.eeg.filtered.rpe.ipe %>%
  filter(subject %in% rpe.good.subjects) %>%
  mutate(rpe=round(rpe, 4)) %>%
  group_by(subject, electrode, t, rpe) %>%
  summarize(m.subject = mean(v)) %>%
  group_by(electrode, t, rpe) %>%
  summarize(m = mean(m.subject), se=sd(m.subject)/sqrt(n()))
```

```{r}
ggplot(abs.plot.data, aes(x=t, y=m, ymin=m-se, ymax=m+se, color=rpe, group=rpe))+
  geom_line()+
  facet_wrap(~electrode)
```

```{r}
abs.plot.data <- data.eeg.filtered.rpe.ipe %>%
  filter(subject %in% ipe.good.subjects) %>%
  mutate(ipe=round(ipe, 4)) %>%
  group_by(subject, electrode, t, ipe) %>%
  summarize(m.subject = mean(v)) %>%
  group_by(electrode, t, ipe) %>%
  summarize(m = mean(m.subject), se=sd(m.subject)/sqrt(n()))
```

```{r}
ggplot(abs.plot.data, aes(x=t, y=m, ymin=m-se, ymax=m+se, color=ipe, group=ipe))+
  geom_line()+
  facet_wrap(~electrode)
```

```{r}
ipe.rpe.counts <- hand.information.minimal.set %>% count(rpe, ipe)

ggplot(ipe.rpe.counts, aes(x=ipe,y=rpe,size=n))+
  geom_point()+
  theme_minimal()
```



- Reprocess data with eye blink removal procedure
- Use a mixed-effects model
- Look for any RPE FRNs. (Is there literature about where else this might show up?)
- Unsigned prediction errors?
- Look at information gain instead of information prediction error.

Descriptive statistics of RPE and IPE.
Means and SD 
Run the joint model, predicting FRN amplitude with RPE and IPE as predictor variables.  [We got here thinking about Camryn’s concern that we measure both in the FRN window.]
Run first half (of the trials), second half, and random half of data to address point that the reward may have become less salient as people figured out what was going on.  Prediction if true:  First half we detect RPE second half we don’t.
Run a model that encodes the strength of the RPE/IPE rather than just +/-.